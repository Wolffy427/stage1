{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9c8cca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export HF_ENDPOINT=https://hf-mirror.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80f9b65",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "Transformers 库将目前的 NLP 任务归纳为几下几类：\n",
    "- 文本分类：例如情感分析、句子对关系判断等；\n",
    "- 对文本中的词语进行分类：例如词性标注 (POS)、命名实体识别 (NER) 等；\n",
    "- 文本生成：例如填充预设的模板 (prompt)、预测文本中被遮掩掉 (masked) 的词语；\n",
    "- 从文本中抽取答案：例如根据给定的问题从一段文本中抽取出对应的答案；\n",
    "- 根据输入文本生成新的句子：例如文本翻译、自动摘要等。\n",
    "\n",
    "Transformers 库最基础的对象就是 pipeline() 函数，它封装了预训练模型和对应的前处理和后处理环节。我们只需输入文本，就能得到预期的答案。目前常用的 pipelines 有：\n",
    "\n",
    "- feature-extraction （获得文本的向量化表示）\n",
    "- fill-mask （填充被遮盖的词、片段）\n",
    "- ner（命名实体识别）\n",
    "- question-answering （自动问答）\n",
    "- sentiment-analysis （情感分析）\n",
    "- summarization （自动摘要）\n",
    "- text-generation （文本生成）\n",
    "- translation （机器翻译）\n",
    "- zero-shot-classification （零训练样本分类）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4baf57cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9598050713539124}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9598050713539124}, {'label': 'NEGATIVE', 'score': 0.9994558691978455}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "result = classifier(\"I've been waiting for a HuggingFace course my whole life.\")\n",
    "print(result)\n",
    "results = classifier(\n",
    "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"]\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f7fc364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhouke/Documents/project/stage1/stage1/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'This is a course about the Transformers library', 'labels': ['education', 'business', 'politics'], 'scores': [0.8445975184440613, 0.11197531223297119, 0.04342718794941902]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "result = classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"]\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c61ca65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': '第35集雪见缓缓张开眼睛，景天又惊又喜之际，长卿和紫萱的仙船驶至，见众人无恙，也十分高兴。众人登船，用尽合力把自身的真气和水分输给她。雪见终于醒过来了，但却一脸木然，全无反应。众人向常胤求助，却发现人世界竟没有雪见的身世纪录。长卿询问清微的身世，清微语带双关说一切上了天界便有答案。长卿驾驶仙船，众人决定立马动身，往天界而去。众人来到一荒山，长卿指出，魔界和天界相连。由魔界进入通过神魔之井，便可登天。众人至魔界入口，仿若一黑色的蝙蝠洞，但始终无法进入。后来花楹发现只要有翅膀便能飞入。于是景天等人打下许多乌鸦，模仿重楼的翅膀，制作数对翅膀状巨物。刚佩戴在身，便被吸入洞口。众人摔落在地，抬头发现魔界守卫。景天和众魔套交情，自称和魔尊重楼相熟，众魔不理，打了起来。',\n",
       " 'answer': '第35集',\n",
       " 'question': '仙剑奇侠传3第几集上天界',\n",
       " 'id': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "\n",
    "class DRQG(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = self.load_data(data_file)\n",
    "\n",
    "    def load_data(self, data_file):\n",
    "        Data = {}\n",
    "        with open(data_file, 'rt') as f:\n",
    "            for idx, line in enumerate(f):\n",
    "                sample = json.loads(line.strip())\n",
    "                Data[idx] = sample\n",
    "        return Data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "train_data = DRQG('./DuReaderQG/train.json')\n",
    "test_data = DRQG('./DuReaderQG/dev.json')\n",
    "\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e42764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': '第35集雪见缓缓张开眼睛，景天又惊又喜之际，长卿和紫萱的仙船驶至，见众人无恙，也十分高兴。众人登船，用尽合力把自身的真气和水分输给她。雪见终于醒过来了，但却一脸木然，全无反应。众人向常胤求助，却发现人世界竟没有雪见的身世纪录。长卿询问清微的身世，清微语带双关说一切上了天界便有答案。长卿驾驶仙船，众人决定立马动身，往天界而去。众人来到一荒山，长卿指出，魔界和天界相连。由魔界进入通过神魔之井，便可登天。众人至魔界入口，仿若一黑色的蝙蝠洞，但始终无法进入。后来花楹发现只要有翅膀便能飞入。于是景天等人打下许多乌鸦，模仿重楼的翅膀，制作数对翅膀状巨物。刚佩戴在身，便被吸入洞口。众人摔落在地，抬头发现魔界守卫。景天和众魔套交情，自称和魔尊重楼相熟，众魔不理，打了起来。',\n",
       " 'answer': '第35集',\n",
       " 'question': '仙剑奇侠传3第几集上天界',\n",
       " 'id': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import IterableDataset\n",
    "import json\n",
    "\n",
    "class IterableDRQG(IterableDataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data_file = data_file\n",
    "    \n",
    "    def __iter__(self):\n",
    "        with open(self.data_file, 'rt') as f:\n",
    "            for line in f:\n",
    "                sample = json.loads(line.strip())\n",
    "                yield sample\n",
    "\n",
    "iter_train_data = IterableDRQG('./DuReaderQG/train.json')\n",
    "\n",
    "next(iter(iter_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1934732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0977cead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我爱自然语言处理'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = tokenizer(\"我爱自然语言处理\", return_tensors=\"pt\")\n",
    "tokenizer.decode(input[\"input_ids\"][0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb9e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = checkpoint = \"langboat/mengzi-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def collote_fn(batch_samples):\n",
    "    batch_questions, batch_context = [], []\n",
    "    batch_answers = []\n",
    "    for sample in batch_samples:\n",
    "        batch_questions.append(sample['question'])\n",
    "        batch_context.append(sample['context'])\n",
    "        batch_answers.append(sample['answer'])\n",
    "    X = tokenizer(\n",
    "        \n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stage1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
